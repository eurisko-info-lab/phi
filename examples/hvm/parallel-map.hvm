// =============================================================================
// HVM4 Example: Parallel Map with Superpositions
// =============================================================================
// Shows how superpositions enable implicit parallelism.

// ---------------------------------------------------------------------------
// A "superposed list" - multiple lists in one structure
// ---------------------------------------------------------------------------
// Instead of computing one result, we compute ALL results at once

// Double a number
@double = λx.(x * 2)

// A superposition of three numbers
@nums = &A{1, &B{2, 3}}
// This represents: 1, 2, and 3 "simultaneously"

// Apply double to the superposition
@main = (@double @nums)
// Result: &A{2, &B{4, 6}}
// We got (double 1), (double 2), and (double 3) all at once!

// ---------------------------------------------------------------------------
// How it works:
// ---------------------------------------------------------------------------
//
// (@double &A{1, &B{2, 3}})
// 
// Step 1: APP-SUP on outer superposition
// ! D &A= @double;
// &A{(D₀ 1), (D₁ &B{2, 3})}
//
// Step 2: DUP-LAM duplicates @double
// ... (the lambda body gets superposed)
//
// Step 3: Continue reducing inner superposition
// &A{(1 * 2), &B{(2 * 2), (3 * 2)}}
//
// Step 4: Compute
// &A{2, &B{4, 6}}
//
// ---------------------------------------------------------------------------
// Why this matters:
// ---------------------------------------------------------------------------
// On a parallel machine (GPU), each branch of the superposition can
// execute on a different core. HVM compiles to massively parallel code
// because the superposition structure explicitly encodes independence.
//
// This is NOT the same as lazy evaluation - it's PARALLEL evaluation
// that emerges naturally from the interaction calculus semantics.

